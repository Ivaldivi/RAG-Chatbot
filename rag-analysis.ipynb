{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d6771b",
   "metadata": {},
   "source": [
    "# RAG Chatbot Analysis\n",
    "Author: Izzy Valdivia\n",
    "\n",
    "\n",
    "### Background: \n",
    "I created a basic chatbot enhanced with RAG. RAGs are used to enhance the knowledge base of a generative LLM to extend the context window or bolster the background on a specific topic. This also means the model does not need to be re-trained to contain specialized information. For example, I decided to use OpenAI's `gpt-5` as the basis for my chatbot and then gave it more context to answer questions specific to Vashon- an Island of ~11k people in the Puget Sound west of Seattle. \n",
    "\n",
    "### Tools: \n",
    "* Model: OpenAI's gpt-5\n",
    "* Database: chromadb\n",
    "* Pdf Parser: pyPDF\n",
    "\n",
    "### Setup: \n",
    "I have included an environment.yml file with all required dependencies.\n",
    "You will need to get an API key from OpenAI in order to run this tutorial. It can be done by running the following command:  \n",
    "`export OPENAI_API_KEY=\"your-api-key\"`  \n",
    "\n",
    "\n",
    "### RAG Testing\n",
    "A cornerstone of a good chatbot is honesty & depth of knowledge. I have specifically instructed the chatbot to admit when it does not have the answer to the question you have asked. The idea behind this request is to reduce the amount of incorrect information that the chatbot provides. Instead of guessing about context from the documents it is referencing, it should encourage you to seek out a different source. \n",
    "\n",
    "Similarly, I have instructed the chatbot to cite its sources. This should allow the user to dig into any of the RAG refernce materials and help make fact-checking faster. \n",
    "\n",
    "I will be testing to see if the chatbot admits when it does not know the answer to the user's question as well as consistently cites its source. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3bdfba",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/personalProjects/rag-llm-app/retreival.py:162\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    158\u001b[39m     file_paths = [\n\u001b[32m    159\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mdocs/Vashon_Washington.pdf\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m    160\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mdocs/Vashon-Maury-history.pdf\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    161\u001b[39m         ]\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     openai_client = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     collection = ingest_context(file_paths, openai_client, \u001b[32m1000\u001b[39m,\u001b[32m200\u001b[39m)\n\u001b[32m    164\u001b[39m        \u001b[38;5;66;03m# Creating an instance of the Chatbot class\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/rag-env/lib/python3.11/site-packages/openai/_client.py:137\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    135\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    141\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "%run retreival.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
